{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to JOJO's Cheat Sheet","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"coding/configs/","title":"Tools &amp; Configuration Cheat sheet","text":""},{"location":"coding/configs/#vim","title":"Vim","text":""},{"location":"coding/configs/#global-configurations","title":"Global Configurations","text":"<pre><code>set nocompatible                \"\u53bb\u6389\u6709\u5173vi\u4e00\u81f4\u6027\u6a21\u5f0f\uff0c\u907f\u514d\u4ee5\u524d\u7248\u672c\u7684bug\u548c\u5c40\u9650\"\nset number\nset relativenumber              \"\u663e\u793a\u884c\u53f7\"\nset guifont=Luxi/Mono/9         \"\u8bbe\u7f6e\u5b57\u4f53\uff0c\u5b57\u4f53\u540d\u79f0\u548c\u5b57\u53f7\"\nfiletype on                     \"\u68c0\u6d4b\u6587\u4ef6\u7684\u7c7b\u578b\"    \nset history=1000                \"\u8bb0\u5f55\u5386\u53f2\u7684\u884c\u6570\"\nset cindent                     \"cindent\u662f\u7279\u522b\u9488\u5bf9 C\u8bed\u8a00\u8bed\u6cd5\u81ea\u52a8\u7f29\u8fdb\"\nset smartindent                 \"\u4f9d\u636e\u4e0a\u9762\u7684\u5bf9\u9f50\u683c\u5f0f\uff0c\u667a\u80fd\u7684\u9009\u62e9\u5bf9\u9f50\u65b9\u5f0f\uff0c\u5bf9\u4e8e\u7c7b\u4f3cC\u8bed\u8a00\u7f16\u5199\u4e0a\u6709\u7528\"\nset tabstop=4                   \"\u8bbe\u7f6etab\u952e\u4e3a4\u4e2a\u7a7a\u683c\"\nset ai!                         \"\u8bbe\u7f6e\u81ea\u52a8\u7f29\u8fdb\"\nset vb t_vb=                    \"\u5f53vim\u8fdb\u884c\u7f16\u8f91\u65f6\uff0c\u5982\u679c\u547d\u4ee4\u9519\u8bef\uff0c\u4f1a\u53d1\u51fa\u8b66\u62a5\uff0c\u8be5\u8bbe\u7f6e\u53bb\u6389\u8b66\u62a5\"\nset ruler                       \"\u5728\u7f16\u8f91\u8fc7\u7a0b\u4e2d\uff0c\u5728\u53f3\u4e0b\u89d2\u663e\u793a\u5149\u6807\u4f4d\u7f6e\u7684\u72b6\u6001\u884c\"\nset incsearch                   \"\u5728\u7a0b\u5e8f\u4e2d\u67e5\u8be2\u4e00\u5355\u8bcd\uff0c\u81ea\u52a8\u5339\u914d\u5355\u8bcd\u7684\u4f4d\u7f6e\uff1b\u5982\u67e5\u8be2desk\u5355\u8bcd\uff0c\u5f53\u8f93\u5230/d\u65f6\uff0c\u4f1a\u81ea\u52a8\u627e\u5230\u7b2c\u4e00\u4e2ad\u5f00\u5934\u7684\u5355\u8bcd\uff0c\u5f53\u8f93\u5165\u5230/de\u65f6\uff0c\u4f1a\u81ea\u52a8\u627e\u5230\u7b2c\u4e00\u4e2a\u4ee5ds\u5f00\u5934\u7684\u5355\u8bcd\uff0c\u4ee5\u6b64\u7c7b\u63a8\uff0c\u8fdb\u884c\u67e5\u627e\uff1b\u5f53\u627e\u5230\u8981\u5339\u914d\u7684\u5355\u8bcd\u65f6\uff0c\u522b\u5fd8\u8bb0\u56de\u8f66\"\nset backspace=2                 \"\u8bbe\u7f6e\u9000\u683c\u952e\u53ef\u7528\"\n</code></pre>"},{"location":"coding/configs/#tmux","title":"Tmux","text":""},{"location":"coding/configs/#default-configurations","title":"Default Configurations","text":"<p>save to ~/.tmux.conf</p> <pre><code># remap prefix to Control + a\n#set -g prefix C-a\n#unbind C-b\n#bind C-a send-prefix\n# force a reload of the config file\n#unbind r\n#bind r source-file ~/.tmux.conf\n# quick pane cycling\n#unbind ^A\nbind -n M-Left select-pane -L\nbind -n M-Right select-pane -R\nbind -n M-Up select-pane -U\nbind -n M-Down select-pane -D\n# window splitting\nbind-key v split-window -h\nbind-key s split-window -v\n# Shift arrow to switch windows\nbind -n S-Left previous-window\nbind -n S-Right next-window\nset-window-option -g aggressive-resize on\n</code></pre>"},{"location":"coding/configs/#scripts-for-installing-stand-alnoe-tmux","title":"Scripts for installing stand alnoe tmux","text":"<pre><code># Script for installing tmux on systems where you don't have root access.\n# tmux will be installed in $HOME/local/bin.\n# It's assumed that wget and a C/C++ compiler are installed.\n\n# exit on error\nset -e\n\nTMUX_VERSION=2.9a\nLIBEVENT_VERSION=2.1.8-stable\nNCURSES_VERSION=6.1\n\n\n# create our directories\nmkdir -p $HOME/local $HOME/tmux_tmp\ncd $HOME/tmux_tmp\n\n# download all the files\nwget https://github.com/tmux/tmux/releases/download/${TMUX_VERSION}/tmux-${TMUX_VERSION}.tar.gz\nwget https://github.com/libevent/libevent/releases/download/release-${LIBEVENT_VERSION}/libevent-${LIBEVENT_VERSION}.tar.gz\nwget https://ftp.gnu.org/pub/gnu/ncurses/ncurses-${NCURSES_VERSION}.tar.gz\n\n############\n# libevent #\n############\ntar xvzf libevent-${LIBEVENT_VERSION}.tar.gz\ncd libevent-${LIBEVENT_VERSION}\n./configure --prefix=$HOME/local --disable-shared\nmake\nmake install\ncd ..\n\n############\n# ncurses  #\n############\ntar xvzf ncurses-${NCURSES_VERSION}.tar.gz\ncd ncurses-${NCURSES_VERSION}\n./configure --prefix=$HOME/local\nmake \nmake install\ncd ..\n\n############\n# tmux     #\n############\ntar xvzf tmux-${TMUX_VERSION}.tar.gz\ncd tmux-${TMUX_VERSION}\n./configure CFLAGS=\"-I$HOME/local/include -I$HOME/local/include/ncurses\" LDFLAGS=\"-L$HOME/local/lib -L$HOME/local/include/ncurses -L$HOME/local/include\"\nCPPFLAGS=\"-I$HOME/local/include -I$HOME/local/include/ncurses\" LDFLAGS=\"-static -L$HOME/local/include -L$HOME/local/include/ncurses -L$HOME/local/lib\" make\ncp tmux $HOME/local/bin\ncd ..\n\ncd $HOME\n\n# cleanup\nrm -rf $HOME/tmux_tmp\n\necho \"$HOME/local/bin/tmux is now available. You can optionally add $HOME/local/bin to your PATH.\"\n\n# for the in order to add to the .bashrc (for /sh/bash) comment-in below line\n# echo 'export PATH=\"$HOME/local/bin:$PATH\"' &gt;&gt; $HOME/.bashrc\n</code></pre>"},{"location":"coding/configs/#stand-alone-code-server-installation","title":"stand-alone code server installation","text":"<p>https://github.com/cdr/code-server/blob/v3.5.0/doc/install.md#standalone-release</p> <pre><code># Sample of .config/code-server/config.yaml\nbind-addr: 0.0.0.0:16666\nauth: password\npassword: 281117\ncert: false\n</code></pre>"},{"location":"coding/configs/#terminator-costum-color-config","title":"Terminator costum color config","text":"<p>overwrite ~/.config/terminator/config</p> <pre><code>[global_config]\n  title_transmit_fg_color = \"#000000\"\n  title_transmit_bg_color = \"#bbede0\"\n[keybindings]\n[profiles]\n  [[default]]\n    background_color = \"#353535\"\n    background_darkness = 0.95\n    background_type = transparent\n    cursor_color = \"#00ff6d\"\n    foreground_color = \"#d3d7cf\"\n    palette = \"#000000:#ef2929:#8ae234:#cdcd00:#729fcf:#cd00cd:#00cdcd:#e5e5e5:#7f7f7f:#cc0000:#73d216:#ffff00:#5c5cff:#ff00ff:#00ffff:#ffffff\"\n[layouts]\n  [[default]]\n    [[[child1]]]\n      parent = window0\n      type = Terminal\n    [[[window0]]]\n      parent = \"\"\n      type = Window\n[plugins]\n</code></pre>"},{"location":"coding/configs/#others","title":"Others","text":"<p>For google drive download on commmand line https://github.com/wkentaro/gdown</p>"},{"location":"coding/envs/","title":"Envs Setup","text":""},{"location":"coding/envs/#mac-setup","title":"Mac Setup","text":"<p>Disable macs key on-hold behaviour for better vscode+vim experience.</p> <p>Reference https://github.com/VSCodeVim/Vim#quick-example</p> <pre><code>$ defaults write com.microsoft.VSCode ApplePressAndHoldEnabled -bool false              # For VS Code\n$ defaults write com.microsoft.VSCodeInsiders ApplePressAndHoldEnabled -bool false      # For VS Code Insider\n$ defaults write com.vscodium ApplePressAndHoldEnabled -bool false                      # For VS Codium\n$ defaults write com.microsoft.VSCodeExploration ApplePressAndHoldEnabled -bool false   # For VS Codium Exploration users\n$ defaults delete -g ApplePressAndHoldEnabled                                           # If necessary, reset global default\n</code></pre> <p>Try lastone and reboot mac.</p> <p>In Preference-&gt;Key board, set key repeat rate to be high and delay until repeat to be low.</p>"},{"location":"coding/envs/#linux","title":"Linux","text":""},{"location":"coding/envs/#sample-bashrc","title":"Sample bashrc","text":"<p>Sample</p>"},{"location":"coding/envs/#setup-ssh-config","title":"Setup ssh config","text":"<pre><code>Host *\n    ControlMaster auto\n    ControlPath ~/.ssh/sockets/%r@%h-%p\n    ControlPersist 1800\n    ServerAliveInterval 60\n    ServerAliveCountMax 30\n</code></pre> <p>remember to mkdir ~/.ssh/sockets</p>"},{"location":"coding/envs/#turning-on-or-off-fn-mode-in-ubuntu-linux","title":"Turning On Or Off Fn Mode In Ubuntu Linux","text":"<pre><code>echo 2 | sudo tee /sys/module/hid_apple/parameters/fnmode\n</code></pre> <p>https://www.hashbangcode.com/article/turning-or-fn-mode-ubuntu-linux</p>"},{"location":"coding/envs/#setup-a-new-device-partition","title":"Setup a new device partition","text":"<p>https://www.digitalocean.com/community/tutorials/how-to-partition-and-format-storage-devices-in-linux</p>"},{"location":"coding/envs/#how-to-migrate-an-existing-miniconda","title":"How to migrate an existing miniconda","text":"<p>This comes in some server where your home directory is almost full. mv the ~/Miniconda or ~/Conda environments to some place else and modify the first line in say:</p> <p></p>"},{"location":"coding/envs/#installupgrade-your-cuda","title":"Install/Upgrade your CUDA","text":"<p>Strictly follow this https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#ubuntu-installation</p> <p>Reboot to make nvidia-smi work.</p> <p>Quick CheetSheet for updating Cuda</p> <p>Solving issue for apt-get update</p> <pre><code>wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin\nsudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600\nsudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/3bf863cc.pub\nsudo add-apt-repository \"deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/ /\"\nsudo apt-get update\n</code></pre> <p>Remove old one and install desired one</p> <pre><code>sudo apt update\nsudo apt purge \"nvidia-*\"\nsudo apt autoremove\nsudo apt auto-clean\nsudo apt-get install cuda-11-8 \n</code></pre> <p>When boot is full checkout https://askubuntu.com/questions/345588/what-is-the-safest-way-to-clean-up-boot-partition</p>"},{"location":"coding/envs/#_1","title":"Envs Setup","text":""},{"location":"coding/cheatsheets/git/","title":"Git","text":""},{"location":"coding/cheatsheets/git/#git-ignore","title":"Git ignore","text":"<p>Use website: https://www.toptal.com/developers/gitignore</p> <p>Sample gitignore file</p>"},{"location":"coding/cheatsheets/git/#setup-a-global-git-ignore-file","title":"Setup a Global Git Ignore File","text":"<pre><code>git config --global core.excludesfile ~/.gitignore_global\n</code></pre>"},{"location":"coding/cheatsheets/linux/","title":"Linux","text":""},{"location":"coding/cheatsheets/linux/#sharing-data-among-groups","title":"Sharing data among groups","text":"<p>https://docs.alliancecan.ca/wiki/Sharing_data</p> <pre><code>setfacl -R -d -m group:def-lsigal:rwx $FOLDER_PATH\n</code></pre>"},{"location":"coding/cheatsheets/linux/#sharing-to-a-user","title":"Sharing to a user","text":"<p>To allow read and write access to a single user in a whole subdirectory, including new files created in it, you can run the following commands:</p> <pre><code>setfacl -d -m u:gabrielh:rwX /home/muchenli/projects/def-lsigal/muchenli\nsetfacl -R -m u:gabrielh:rwX /home/muchenli/projects/def-lsigal/muchenli\n</code></pre>"},{"location":"coding/cheatsheets/ohmyzsh/","title":"Oh-my-zsh","text":""},{"location":"coding/cheatsheets/ohmyzsh/#install-oh-my-zsh","title":"Install oh my zsh","text":"<pre><code>sh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"\n( cd $ZSH_CUSTOM/plugins &amp;&amp; git clone https://github.com/chrissicool/zsh-256color )\ngit clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions\n</code></pre> <p>Then change line in ~/.zshrc to</p> <pre><code>plugins=(git zsh-autosuggestions zsh-256color)\n</code></pre>"},{"location":"coding/cheatsheets/slurm/","title":"Slurm","text":""},{"location":"coding/cheatsheets/slurm/#slurm-cheat-sheet","title":"Slurm Cheat Sheet","text":"<p>https://slurm.schedmd.com/pdfs/summary.pdf</p> <pre><code>alias sq='squeue -u muchenli -o \"%.18i %.9P %.25j %.8u %.8T %.10M %.9l %.6D %R\"'\nalias sqp='squeue -p edith -o \"%.18i %.9P %.25j %.8u %.10T %.15M %.15l %5D %12R %b\"'\nalias si='sinfo -O \"NodeHost:10\",\"StateCompact:6\",\"CPUsState:14\",\"Memory:7\",\"AllocMem:9\",\"FreeMem:9\",\"GresUsed:55\",\"Gres:55\" -p edith'\n</code></pre>"},{"location":"coding/cheatsheets/slurm/#slurm-submission-script","title":"Slurm Submission script","text":"<p>Submission script for computecananda, vector, and Leon's server. Runing this script will automatically generate sbatch submission file and submit the job to slurm system.</p> <pre><code>#!/usr/bin/env python3\n# by muchenli\n# modified from https://github.com/ubc-vision/compute-canada-goodies/blob/master/python/queue_cc.py\n\nimport argparse\nimport getpass\nimport os\nimport shutil\nimport time\nimport socket\nimport subprocess\nimport datetime\n\nCLUSTER_CONFIG = {\n    \"cedar\":\n        {\n            \"gpu_model\": \"v100l\",\n            \"gpus_per_node\": 4,\n            \"cpu_cores_per_node\": 24,\n            \"threads_per_node\": 48,\n            \"cpu_cores_per_gpu\": 6,\n            \"threads_per_gpu\": 12,\n            \"ram_per_node\": 120,\n            \"ram_per_gpu\": 24,\n            \"job_system\": \"slurm\",\n            \"partition\": None,\n            \"nodelist\": None,\n            \"default_account\": \"rrg-lsigal\",\n        },\n    # \"sockeye\":\n    #     {\n    #         \"gpu_model\": \"v100\",\n    #         \"gpus_per_node\": 4,\n    #         \"cpu_cores_per_node\": 24,\n    #         \"threads_per_node\": None,\n    #         \"cpu_cores_per_gpu\": 6,\n    #         \"threads_per_gpu\": None,\n    #         \"ram_per_node\": 191000,\n    #         \"ram_per_gpu\": 47750,\n    #         \"job_system\": \"PBS\",\n    #         \"partition\": None,\n    #         \"nodelist\": None,\n    #         \"default_account\": \"pr-kmyi-1\",\n    #         \"default_gpu_account\": \"pr-kmyi-1-gpu\",\n    #     },\n    \"edith\":\n        {\n            \"cpu_cores_per_gpu\": 2,\n            \"ram_per_gpu\": 8,\n            \"job_system\": \"slurm\",\n            \"partition\": \"edith\",\n            \"nodelist\": None,\n            \"default_account\": None\n        },\n    \"vector\":\n        {\n            \"cpu_cores_per_gpu\": 8,\n            \"ram_per_gpu\": 40,\n            \"job_system\": \"slurm\",\n            \"partition\": \"a40\",\n            \"nodelist\": None,\n            \"default_account\": None\n        }\n}\n\n# User NOTE: Add python environment init command here\nENV_INIT_COMMAND = {\n    \"vector\": \"source ~/setup.sh\\n\"\n              \"conda activate pt\\n\"\n              \"export PYTHONPATH=./\\n\",\n    \"edith\": \"conda activate nni\\n\"\n             \"export GLOO_SOCKET_IFNAME='eno1'\\n\" # https://pytorch.org/docs/stable/distributed.html#common-environment-variables\n             \"export TP_SOCKET_IFNAME='eno1'\",  # This is required to make sure rpc works correctly on Edith\n    \"cedar\": \"source ~/torch/bin/activate\\n\"\n             \"export PYTHONPATH=./\",\n}\n\n# DIST_INIT_COMMAND = \"export MASTER_ADDR=$(hostname)\"\n\nDATA_INIT_COMMAND = {\n    \"tiny-imagenet\": \"mkdir $SLURM_TMPDIR/tiny-imagenet\\n\"\n    \"cp ~/projects/def-lsigal/muchenli/DATASET/tiny-imagenet-200/tiny-imagenet.hdf5 $SLURM_TMPDIR/tiny-imagenet/\"\n}\n\n# User NOTE: customize your commands here:\n# here I add command line exp_name to my output path\ndef customize_command(commands):\n    # exp_name = os.getenv(\"SID\", \"DEFAULT\")\n    # for i, c in enumerate(commands):\n    #     if c == '--config-file':\n    #         config_path = commands[i+1].split('config/', 1)[-1].rsplit('.', 1)[0]\n    # commands.append('OUTPUT_DIR')\n    # commands.append(os.path.join('.exps', config_path, exp_name))\n    return commands\n\ndef customize_script(script_lines):\n    # if args.load_data == 'tiny-imagenet' and cluster in ['cedar', 'narval']:\n    #     script_lines.append(DATA_INIT_COMMAND[args.load_data])\n    return script_lines\n\ndef get_slurm_script(args, cluster_name, dep_str=None):\n    d = {}\n    default_cfg = CLUSTER_CONFIG[cluster_name]\n\n    num_gpu = args.num_gpu\n    # Set options which could be None\n    d[\"account\"] = default_cfg[\"default_account\"] if args.account is None else args.account\n    d[\"partition\"] = default_cfg[\"partition\"] if args.partition is None else args.partition\n    d[\"nodelist\"] = default_cfg[\"nodelist\"] if args.nodelist is None else args.nodelist\n    # Set options or automatically infer CPU and MEM\n    num_cpu = default_cfg[\"cpu_cores_per_gpu\"] * num_gpu if args.num_cpu &lt; 0 else args.num_cpu\n    d[\"cpus-per-task\"] = max(num_cpu // args.ntasks_per_node, 1)\n    mem = default_cfg[\"ram_per_gpu\"] * num_gpu if args.mem &lt; 0 else args.mem        \n    d[\"mem\"] = str(max(mem, default_cfg[\"ram_per_gpu\"]))+'G'\n    # Set universal needed options\n    d[\"nodes\"] = args.nodes\n    d[\"ntasks-per-node\"] = args.ntasks_per_node\n    d[\"time\"] = args.time_limit\n    d[\"output\"] = f\"{args.log_dir}/{time.strftime('%m%d')}_%x_%j.out\"\n    d[\"mail-user\"] = \"jojo23333.code@gmail.com\"\n    d[\"mail-type\"] = \"BEGIN,FAIL\"\n    d[\"export\"] = \"ALL\"\n\n    if cluster_name == 'vector':\n        d[\"qos\"] = \"normal\"\n        # d[\"qos\"] = \"deadline\"\n        # d[\"account\"] = \"deadline\"\n        if num_gpu == 1 and args.nodes == 1:\n            d['partition'] = 'rtx6000'\n\n    # Generate script\n    script_lines=[\"#!/bin/bash\"]\n    if num_gpu &gt; 0:\n        if cluster_name == 'cedar':\n            script_lines.append(f\"#SBATCH --gres=gpu:v100l:{num_gpu}\")\n        else:\n            script_lines.append(f\"#SBATCH --gres=gpu:{num_gpu}\")\n    for key, value in d.items():\n        if value is not None:\n            script_lines.append(f\"#SBATCH --{key}={str(value)}\")\n    # if run with dependency\n    if dep_str is not None:\n        script_lines.append(f\"#SBATCH --dependency=afterany:{dep_str}\")\n    if args.exclude is not None:\n        script_lines.append(f\"#SBATCH --exclude={args.exclude}\")\n    script_lines.append(\"\")\n    return d, script_lines\n\n\ndef main(args):\n    if not os.path.exists(args.log_dir):\n        os.makedirs(args.log_dir)\n\n    if not os.path.exists(args.script_dir):\n        os.makedirs(args.script_dir)\n\n    # Get hostname and user name\n    username = getpass.getuser()\n    hostname = socket.gethostname()\n\n    # Identify cluster\n    if config.cluster is None:\n        if hostname.startswith(\"gra\"):\n            cluster = \"graham\"\n        elif hostname.startswith(\"cedar\") or hostname.startswith(\"cdr\"):\n            cluster = \"cedar\"\n        elif hostname.startswith(\"beluga\") or hostname.startswith(\"blg\"):\n            cluster = \"beluga\"\n        # elif hostname.startswith(\"se\"):\n        #     cluster = \"sockeye\"\n        elif hostname.startswith(\"narval\"):\n            cluster = \"narval\"\n        elif hostname.startswith(\"borg\"):\n            cluster = \"edith\"\n        elif hostname.startswith(\"vremote\"):\n            cluster = \"vector\"\n        else:\n            raise ValueError(\"Unknown cluster {}\".format(hostname))\n    else:\n        cluster = config.cluster\n\n    dep_str = None\n    for i in range(args.repeat):\n        # set time limit\n        config_d, script_lines = get_slurm_script(args, cluster, dep_str)\n        script_lines.append(ENV_INIT_COMMAND[cluster])\n        # script_lines.append(DIST_INIT_COMMAND)\n        script_lines = customize_script(script_lines)\n        command = customize_command(list(args.command))\n\n        exp_name = os.getenv(\"SID\", default='test') + (f'_{i+1}.sh' if i &gt; 0 else '.sh')\n        bash_file_path = os.path.join(args.script_dir, exp_name)\n\n        with open(bash_file_path, 'w') as f:\n            for line in script_lines:\n                f.write(line + '\\n')\n            f.write('srun ')\n            if cluster == 'vector':\n                f.write(f'--mem={config_d[\"mem\"]} ')\n            f.write(' '.join(command))\n            f.close()\n\n        # legacy code to run 1 job\n        # bash_file_path = os.path.abspath(bash_file_path)\n        # print(f\"sbatch {bash_file_path}\", os.path.exists(bash_file_path))\n        # os.system(f\"sbatch {bash_file_path}\")\n\n        # run command with subprocess\n        slurm_res = subprocess.run([\"sbatch\", f\"{bash_file_path}\"], stdout=subprocess.PIPE)\n        print(slurm_res.stdout.decode())\n        # get job ID, potentially use it for conditional job submitting\n        if slurm_res.returncode != 0:\n            raise RuntimeError(\"Slurm/PBS error!\")\n        job_id = slurm_res.stdout.decode().split()[-1]\n        dep_str = str(job_id)\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--account\", type=str, default=None, help=\"Slurm account to use. \")\n    parser.add_argument(\"--cluster\", type=str, default=None, help=\"Name of the cluster.\")\n    parser.add_argument(\"--log_dir\", type=str, default=\".exps/slurm_log\", help=\"\")\n    parser.add_argument(\"--script_dir\", type=str, default=\".exps/cc_scripts\", help=\"\")\n    parser.add_argument(\"--load_data\", type=str, default=\"\", help=\"Some customize op to pre-load data\")\n    # Per job Arguments\n    parser.add_argument(\"--num_runs\", type=int, default=5, help=\"Number of times this shell script will be executed. This is useful when running 3 hour jobs that run multiple times.\")\n    parser.add_argument(\"--nodes\", type=int, default=1)\n    parser.add_argument(\"--ntasks_per_node\", type=int, default=1)\n    parser.add_argument(\"--num_gpu\", type=int, default=1, help=\"Number of GPUs Per Node. Set zero to not use the gpu node.\")\n    parser.add_argument(\"--num_cpu\", type=int, default=-1, help=\"Number of CPU cores to use. Set -1 for auto inference.\")\n    parser.add_argument(\"--mem\", type=int, default=-1, help=\"Amount of memory to use. See compute canada wiki. Typically, &lt;= 8G per CPU core. Set -1 for auto inference.\")\n    parser.add_argument(\"--time_limit\", type=str, default=\"02-23:59\", help=\"Time limit on the jobs.  Day-time-minutes\")\n    parser.add_argument(\"--partition\", type=str, default=None, help=\"Partition to be used.\")\n    parser.add_argument(\"--nodelist\", type=str, default=None, help=\"List of nodes to be used.\")\n    parser.add_argument(\"--exclude\", type=str, default=None, help=\"List of nodes to be excluded.\")\n    parser.add_argument(\"--repeat\", type=int, default=1, help=\"Number of times to repeat the job, add dependency auotomatically\")\n\n    parser.add_argument(\"command\", default=None, nargs=argparse.REMAINDER)\n\n    config, unparsed = parser.parse_known_args()\n    assert config.command is not None\n    # If we have unparsed arguments, print usage and exit\n    if len(unparsed) &gt; 0:\n        parser.print_usage()()\n        exit(1)\n\n    main(config)\n</code></pre> <p>use case</p> <pre><code># SID=exp_name python scripts/submit.py --nodes 2 --num_gpu 4 --ntasks_per_node 1 --time_limit ...\n</code></pre> <p>it will automatically detect your cluster.</p> <ul> <li>This script will generate a $SID.sh sbatch file in --script_dir and then launch it. Result stored in --log_dir.</li> <li>Use --repeat to split 1 job to multiple small sub jobs with dependency, tricks works on compute cananda</li> </ul>"},{"location":"coding/python/bitter_lessons/","title":"Bitter Lessons","text":""},{"location":"coding/python/bitter_lessons/#reason-not-to-use-xy","title":"Reason not to use [x]*y","text":"<pre><code>x = [[0]*3] * 3\nprint(x)\nx[1][1] = 1\nprint(x)\n</code></pre> <p>gives:</p> <pre><code>[[0, 0, 0], [0, 0, 0], [0, 0, 0]]\n[[0, 1, 0], [0, 1, 0], [0, 1, 0]]\n</code></pre> <p>Correct way to do it:</p> <pre><code>x = [[0]*3 for i in range(3)]\nprint(x) \nx[1][1] = 1\nprint(x)\n</code></pre>"},{"location":"coding/python/pytorch/","title":"Pytorch cheat sheet","text":""},{"location":"coding/python/pytorch/#model-zoo","title":"Model ZOO","text":"<p>set variable TORCH_HOME or TORCH_MODEL_ZOO for torch &lt; 1.7 https://pytorch.org/docs/stable/hub.html</p>"},{"location":"coding/python/pytorch/#reference-to-use-einstein-sum","title":"Reference to use Einstein Sum","text":"<p>https://rockt.github.io/2018/04/30/einsum</p> <p>https://obilaniu6266h16.wordpress.com/2016/02/04/einstein-summation-in-numpy/</p>"},{"location":"coding/python/pytorch/#einops","title":"Einops:","text":"<p>https://openreview.net/forum?id=oapKSVM2bcj</p>"},{"location":"coding/python/tips/","title":"Python tips","text":""},{"location":"coding/python/tips/#some-python-tips","title":"Some python tips","text":""},{"location":"coding/python/tips/#pip-install-using-other-cache-dir","title":"pip install using other cache dir","text":"<p>https://github.com/pypa/pip/issues/5816</p> <pre><code>TMPDIR=/data/vincents/ pip install --cache-dir=/data/vincents/ --build /data/vincents/ tensorflow-gpu\n</code></pre>"},{"location":"coding/python/tips/#tips-for-passing-reference-in-python","title":"Tips for passing reference in python","text":"<p>Python's variable are generally different than that in other languages, see below figure for a straightforward illustration.</p> <p></p> <p>see https://stackoverflow.com/questions/986006/how-do-i-pass-a-variable-by-reference for more info.</p>"},{"location":"coding/python/tips/#useful-debugging-tools","title":"Useful debugging tools","text":"<p>IPDB https://pypi.org/project/ipdb/</p>"},{"location":"coding/python/tips/#deploy-your-code-to-server","title":"Deploy your code to server","text":"<p>Vscode Deploy Plugin</p>"},{"location":"coding_loggs/ddp_with_buffer/","title":"Ddp with buffer","text":""},{"location":"coding_loggs/ddp_with_buffer/#use-ddp-with-module-buffer-goes-run","title":"Use ddp with module buffer goes run","text":"<p>Running MDM with ddp version, https://github.com/GuyTevet/motion-diffusion-model</p> <p>Runs into </p> <pre><code>RuntimeError: unsupported operation: some elements of the input tensor and the written-to tensor refer to a single memory location\n</code></pre> <p>Related to DDP should not use buffer, but use parameter with require_grad=False</p> <p>See https://github.com/Lightning-AI/lightning/discussions/14377</p>"},{"location":"research/latex/","title":"Latex cheat sheet","text":""},{"location":"research/latex/#figures-and-tables","title":"Figures and Tables","text":"<p>Cetering of figures https://www.overleaf.com/learn/latex/Positioning_of_Figures</p>"},{"location":"research/latex/#notations","title":"Notations","text":""},{"location":"research/latex/#docs","title":"Docs","text":""},{"location":"research/latex/#deletetion-lines","title":"Deletetion lines","text":""},{"location":"research/latex/#useful-staffs","title":"Useful staffs","text":""},{"location":"research/latex/#import-colorful-codes","title":"Import colorful codes","text":"<p>Checkout overleaf instructions to use formated codes.</p> <pre><code>\\documentclass{article}\n\\usepackage[utf8]{inputenc}\n\n\\usepackage{listings}\n\\usepackage{xcolor}\n\n\\definecolor{codegreen}{rgb}{0,0.6,0}\n\\definecolor{codegray}{rgb}{0.5,0.5,0.5}\n\\definecolor{codepurple}{rgb}{0.58,0,0.82}\n\\definecolor{backcolour}{rgb}{0.95,0.95,0.92}\n\n\\lstdefinestyle{mystyle}{\n    backgroundcolor=\\color{backcolour},   \n    commentstyle=\\color{codegreen},\n    keywordstyle=\\color{magenta},\n    numberstyle=\\tiny\\color{codegray},\n    stringstyle=\\color{codepurple},\n    basicstyle=\\ttfamily\\footnotesize,\n    breakatwhitespace=false,         \n    breaklines=true,                 \n    captionpos=b,                    \n    keepspaces=true,                 \n    numbers=left,                    \n    numbersep=5pt,                  \n    showspaces=false,                \n    showstringspaces=false,\n    showtabs=false,                  \n    tabsize=2\n}\n\n\\lstset{style=mystyle}\n\n\\begin{document}\nThe next code will be directly imported from a file\n\n\\lstinputlisting[language=Octave]{BitXorMatrix.m}\n\\end{document}\n</code></pre> <p>To use it</p> <pre><code>\\begin{lstlisting}[language=Python, caption=Python example]\n    Your code\n\\end{lstlisting}\n</code></pre> <p>It looks like this: </p>"},{"location":"research/latex/#personal-commands","title":"Personal commands","text":"<pre><code>% declare normal emphasize for instead of undelining\n\\usepackage[normalem]{ulem}\n% add comment using \\muchen\n\\newcommand {\\muchen}[1]{{\\color{blue}#1}}\n% do modification by using \\md{old_content}{new_content}\n\\newcommand {\\md}[2]{\\sout{#1}{ \\color{blue}#2}}\n</code></pre>"},{"location":"research/latex/#latex-enumitem","title":"latex \u4f7f\u7528 enumitem \u5b8f\u5305\u8c03\u6574\u4e0a\u4e0b\u5de6\u53f3\u7f29\u8fdb\u95f4\u8ddd\uff0c\u6807\u7b7e\u6837\u5f0f","text":"<p>https://blog.csdn.net/robert_chen1988/article/details/83179571</p>"},{"location":"research/math/","title":"Math","text":""},{"location":"research/math/#notation-tools","title":"notation tools","text":"<p>Iverson bracket as conditional value: https://en.wikipedia.org/wiki/Iverson_bracket</p>"},{"location":"research/softwares/","title":"Softwares Recommendation","text":""},{"location":"research/softwares/#free-countdown-timer","title":"Free countdown timer","text":"<p>https://free-countdown.com/</p>"},{"location":"research/softwares/#zotero-paper-management","title":"Zotero paper management","text":"<p>If you are using Mendeley, you can export mendeley's paper by installing medeley version &lt;= 1.8.</p> <p>Zotero has a bunch of useful plugins.</p>"},{"location":"research/softwares/#connect-to-remote-desktop-with-gui","title":"Connect to Remote Desktop with GUI","text":"<p>TeamViewer or No Machine https://www.nomachine.com/</p>"},{"location":"research/softwares/#endnote","title":"Endnote","text":""},{"location":"research/softwares/#import-from-plain-reference-txt-to-endnote","title":"Import from plain reference txt to endnote","text":"<p>https://zhuanlan.zhihu.com/p/468786236</p> <p>https://www.cnblogs.com/larissa-0464/p/14166577.html</p>"},{"location":"research/vector_cluster_guide/","title":"Vector","text":""},{"location":"research/vector_cluster_guide/#before-start","title":"Before start","text":"<ul> <li>Vector's document is a bit of out-dataed, but is a still useful reference: Vector Computing Please note you have to use your login credential.</li> <li>If you are affiliated with vector, consider to join vector's slack channel where you can reachout to IT over(#Computing Channel)</li> <li>Learn how to login and which cluster to use, now you need to setup duo-factor credentials, you should find email sent to you if you are affiliated.</li> </ul>"},{"location":"research/vector_cluster_guide/#storage-and-compute-resources","title":"Storage and Compute Resources","text":"<p>Compute Storage All new users will have their SSD scratch space in \"/scratch/ssd004/scratch/$USER/\" with a quota of 100 GB.</p> <p>Pls consider reach out to IT over SLACK</p>"},{"location":"research/vector_cluster_guide/#environment-setting","title":"Environment Setting","text":"<p>Use conda provided by vector or install your own ones</p> <pre><code>export PATH=/pkgs/anaconda3/bin:$PATH\nwhich Conda\n</code></pre> <p>Environment Setup</p>"},{"location":"research/vector_cluster_guide/#submitting-jobs","title":"Submitting Jobs","text":"<p>Available Compute Nodes</p> <p>Submit Jobs</p>"},{"location":"research/vector_cluster_guide/#vaughan-preemption-and-checkpointing","title":"Vaughan preemption and checkpointing","text":"<p>Vanughan use a preemption policy to make sure every job has a chance of being runned. Please see details here: Policy details</p> <p>Important: Since any job can be preempted, please make sure your running jobs can auto resume it self if it's rerunned</p>"},{"location":"research/vector_cluster_guide/#easy-script-for-submitting-jobs-integrated-with-compute-canand","title":"Easy Script for submitting jobs (Integrated with Compute Canand)","text":"<p>I wrote a (script)[https://jojoml.github.io/jojodoc/coding/cheatsheets/slurm/] for esay submitting jobs for vector and compute canada.</p> <p>Page editted on May 22st. Will be updated.</p>"},{"location":"research/website/","title":"Build static website","text":""},{"location":"research/website/#academic-personal-page","title":"Academic Personal Page","text":"<p>framework: jekyll</p> <p>theme: al-folio</p>"},{"location":"research/website/#personal-docs","title":"Personal docs","text":"<p>framework: mkdocs</p> <p>theme: mkdocs-material</p>"}]}